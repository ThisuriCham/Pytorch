{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom-transform.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThisuriCham/Pytorch/blob/master/custom_transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSvAWbby01FA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rescale\n",
        "class Rescale(object):\n",
        "  ''' rescale the image in a sample to given size.\n",
        "  \n",
        "  Args: \n",
        "  output_size(tuple or int): desired output size.\n",
        "  if tuple, output is matched to output_size. \n",
        "  if int, smaller of image edges is matched to \n",
        "  output_size keeping aspect ration the same. \n",
        "  '''\n",
        "\n",
        "  def __init__(self, output_size):\n",
        "    assert isinstance(output_size, (int,tuple))\n",
        "    self.output_size = output_size\n",
        "\n",
        "  def __call__(self,sample):\n",
        "    image, landmarks = sample['image'], sample['landmarks']\n",
        "\n",
        "    h, w = image.shape[:2]\n",
        "    if isinstance(self.output_size, int):\n",
        "       if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        img = transform.resize(image, (new_h, new_w))\n",
        "\n",
        "        # h and w are swapped for landmarks because for images,\n",
        "        # x and y axes are axis 1 and 0 respectively\n",
        "        landmarks = landmarks * [new_w / w, new_h / h]\n",
        "\n",
        "        return {'image': img, 'landmarks': landmarks}\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtAZGdfI5vZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#randomcrop\n",
        "class RandomCrop(object):\n",
        "  ''' \n",
        "  Crop randomly the image in a sample.\n",
        "\n",
        "  Args:\n",
        "  output_size (tuple or int): desired output size. \n",
        "  If int, square crop is made.\n",
        "   '''\n",
        "\n",
        "   def __init__(self, output_size):\n",
        "     assert isinstance(output_size, (int, tuple))\n",
        "     if isinstance(output_size, int):\n",
        "       self.output_size = (output_size, output_size)\n",
        "     else:\n",
        "       assert len(output_size) == 2\n",
        "       self.output_size = output_size\n",
        "\n",
        "   def __call__(self,sample):\n",
        "     image, landmarks = sample['image'],sample['landmarks']\n",
        "     h, w = image.shape[:2]\n",
        "     new_h, new_w = self.output_size\n",
        "\n",
        "     top = np.random.randint(0, h-new_h)\n",
        "     left = np.random.randint(0, w-new_w)\n",
        "\n",
        "     image = image[top: top+new_h, left: left+new_w]\n",
        "\n",
        "     landmarks = landmarks - [left,top]\n",
        "\n",
        "     return {'image': image, 'landmarks':landmarks}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUAOzqNSUdQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToTensor(object):\n",
        "  ''' convert ndarrays in sample to tensors '''\n",
        "  def __call__(self,sample):\n",
        "    image, landmarks = sample['image'],sample['landmarks']\n",
        "\n",
        "    #swap color axis\n",
        "    #numpy image: HxWxC\n",
        "    #torch image: CxHxW\n",
        "\n",
        "    image = image.transpose((2,0,1))\n",
        "    return{'image':torch.from_numpy(image),'landmarks':torch.from_numpy(landmarks)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXlp03lukx9r",
        "colab_type": "text"
      },
      "source": [
        "**Collate_fn**: this is the function that processes the batch that you want to return from your dataloader.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YegYAAmXJhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformed_dataset = FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv',root_dir = 'data/faces/',transform=transforms.compose([Rescale(256),RandomCrop(224),ToTensor()]))\n",
        "\n",
        "dataloader = DataLoader(transformed_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
        "\n",
        "#helper function to show a batch\n",
        "def show_landmarks_batch(sample_batched):\n",
        "  ''' show image with landmarks for a batch os sample '''\n",
        "   images_batch, landmarks_batch = \\\n",
        "            sample_batched['image'], sample_batched['landmarks']\n",
        "    batch_size = len(images_batch)\n",
        "    im_size = images_batch.size(2)\n",
        "    grid_border_size = 2\n",
        "\n",
        "    grid = utils.make_grid(images_batch)\n",
        "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1) * grid_border_size,\n",
        "                    landmarks_batch[i, :, 1].numpy() + grid_border_size,\n",
        "                    s=10, marker='.', c='r')\n",
        "\n",
        "        plt.title('Batch from dataloader')\n",
        "\n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    print(i_batch, sample_batched['image'].size(),\n",
        "          sample_batched['landmarks'].size())\n",
        "\n",
        "    # observe 4th batch and stop.\n",
        "    if i_batch == 3:\n",
        "        plt.figure()\n",
        "        show_landmarks_batch(sample_batched)\n",
        "        plt.axis('off')\n",
        "        plt.ioff()\n",
        "        plt.show()\n",
        "        break\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}